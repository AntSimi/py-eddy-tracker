#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
===============================================================================
This file is part of py-eddy-tracker.

    py-eddy-tracker is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    py-eddy-tracker is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with py-eddy-tracker.  If not, see <http://www.gnu.org/licenses/>.

Copyright (c) 2014-2015 by Evan Mason
Email: emason@imedea.uib-csic.es
"""

import logging
from glob import glob
from yaml import load as yaml_load
from datetime import datetime
import datetime as dt
from scipy.ndimage import gaussian_filter
from matplotlib.dates import date2num, num2julian
from matplotlib.figure import Figure
from re import compile as re_compile
from os.path import exists
from os import mkdir
from multiprocessing import Pool
import numpy as np

from py_eddy_tracker import EddyParser
from py_eddy_tracker.property_functions import \
    collection_loop, func_hann2d_fast
from py_eddy_tracker.property_objects import SwirlSpeed
from py_eddy_tracker.grid.aviso import AvisoGrid
from py_eddy_tracker.tracking_objects import IdentificationList


def circle_process(paths):
    nb_proc = 4
    def fit_circle_path(item):
        item._fit_circle_path()
    threads = Pool(nb_proc)
    threads.map(fit_circle_path, paths)

if __name__ == '__main__':
    # Run using:
    PARSER = EddyParser("Tool to detect eddies. "
                        "To run use EddyIdentification "
                        "eddy_tracker_configuration.yaml'")
    PARSER.add_argument('yaml_file',
                        help='Yaml file to configure py-eddy-tracker')
    YAML_FILE = PARSER.parse_args().yaml_file

    # Read yaml configuration file
    with open(YAML_FILE, 'r') as stream:
        CONFIG = yaml_load(stream)

    logging.info('Launching with yaml file: %s', YAML_FILE)

    # Setup configuration
    SAVE_DIR = CONFIG['PATHS']['SAVE_DIR']
    if not exists(SAVE_DIR):
        mkdir(SAVE_DIR)
    logging.info('Outputs saved to %(SAVE_DIR)s', CONFIG['PATHS'])

    DIAGNOSTIC_TYPE = CONFIG['DIAGNOSTIC_TYPE']
    if DIAGNOSTIC_TYPE not in ['SLA']:
        raise Exception('Unknown diagnostic %s', DIAGNOSTIC_TYPE)

    CONFIG['THE_DOMAIN'] = CONFIG['DOMAIN']['THE_DOMAIN']

    # It is not recommended to change values given below
    # for 'Global', 'BlackSea' or 'MedSea'...
    if 'Global' in CONFIG['THE_DOMAIN']:
        CONFIG['lonmin'] = -100.
        CONFIG['lonmax'] = 290.
        CONFIG['latmin'] = -80.
        CONFIG['latmax'] = 80.

    elif CONFIG['THE_DOMAIN'] in ('Regional'):
        CONFIG['lonmin'] = CONFIG['DOMAIN']['LONMIN']
        CONFIG['lonmax'] = CONFIG['DOMAIN']['LONMAX']
        CONFIG['latmin'] = CONFIG['DOMAIN']['LATMIN']
        CONFIG['latmax'] = CONFIG['DOMAIN']['LATMAX']

    START_DATE = CONFIG['DATE_STR'] = CONFIG['DOMAIN']['DATE_STR']
    END_DATE = CONFIG['DATE_END'] = CONFIG['DOMAIN']['DATE_END']
    if START_DATE > END_DATE:
        raise Exception('DATE_END must be larger than DATE_STR')

    if 'SLA' in DIAGNOSTIC_TYPE:
        MAX_SLA = CONFIG['CONTOUR_PARAMETER'
                         ]['CONTOUR_PARAMETER_SLA']['MAX_SLA']
        INTERVAL = CONFIG['CONTOUR_PARAMETER'
                          ]['CONTOUR_PARAMETER_SLA']['INTERVAL']
        CONFIG['CONTOUR_PARAMETER'] = np.arange(-MAX_SLA, MAX_SLA + INTERVAL,
                                                INTERVAL)
        # AMPMIN = CONFIG['AMPMIN']
        # AMPMAX = CONFIG['AMPMAX']

    SMOOTHING = CONFIG['SMOOTHING']
    if SMOOTHING:
        if 'SLA' in DIAGNOSTIC_TYPE:
            ZWL = np.atleast_1d(CONFIG['SMOOTHING_SLA']['ZWL'])
            MWL = np.atleast_1d(CONFIG['SMOOTHING_SLA']['MWL'])
        SMOOTHING_TYPE = CONFIG['SMOOTHING_SLA']['TYPE']

    # End user configuration setup options
    # ----------------------------------------------------------

    # Get complete AVISO file list
    DATA_DIR = CONFIG['DATASET']['DATA_DIR']
    FILES_MODEL = CONFIG['DATASET']['FILES_MODEL']
    SUBSAMPLING_STEP = CONFIG['DATASET']['SUBSAMPLING']
    DATE_REGEXP = re_compile('.*/' + CONFIG['DATASET']['DATE_REGEXP'])
    PATTERN_DATE = CONFIG['DATASET']['DATE_MODEL']

    GRID_NAME = CONFIG['DATASET']['VAR_NAME']
    LAT_NAME = CONFIG['DATASET']['LAT_NAME']
    LON_NAME = CONFIG['DATASET']['LON_NAME']

    DATASET_FILES = glob(DATA_DIR + FILES_MODEL)

    DATASET_LIST = np.array(DATASET_FILES,
                            dtype=[('date', 'datetime64[D]'),
                                   ('filename', 'S256')])
    DATASET_LIST['filename'] = np.array(DATASET_FILES)

    logging.info('%s grids available', DATASET_LIST.shape[0])
    for item in DATASET_LIST:
        result = DATE_REGEXP.match(item['filename'])
        if result:
            str_date = result.groups()[0]
            item['date'] = datetime.strptime(str_date, PATTERN_DATE).date()

    DATASET_LIST.sort(order=['date', 'filename'])
    MASK_DATE = (DATASET_LIST['date'] >= START_DATE) * (
        DATASET_LIST['date'] <= END_DATE)

    STEPS = np.unique(DATASET_LIST['date'][1:] - DATASET_LIST['date'][:-1])
    if len(STEPS) != 1:
        raise Exception('Several days steps in grid dataset %s' % STEPS)
    else:
        DAYS_BTWN_RECORDS = STEPS[0]

    if SUBSAMPLING_STEP != 1:
        logging.info('Grid subsampling %d', SUBSAMPLING_STEP)
        DATASET_LIST = DATASET_LIST[::SUBSAMPLING_STEP]

    DATASET_LIST = DATASET_LIST[MASK_DATE]

    # Set up a grid object using first AVISO file in the list
    SLA_GRD = AvisoGrid(DATASET_LIST[0]['filename'], CONFIG['THE_DOMAIN'],
                        CONFIG['lonmin'], CONFIG['lonmax'],
                        CONFIG['latmin'], CONFIG['latmax'],
                        grid_name=GRID_NAME,
                        lon_name=LON_NAME,
                        lat_name=LAT_NAME)

    if 'Gaussian' in SMOOTHING_TYPE:
        # Get parameters for gaussian_filter
        ZRES, MRES = SLA_GRD.gaussian_resolution(ZWL, MWL)

    # See Chelton section B2 (0.4 degree radius)
    # These should give 8 and 1000 for 0.25 deg resolution
    PIXMIN = np.round((np.pi * CONFIG['RADMIN'] ** 2) /
                      SLA_GRD.resolution ** 2)
    PIXMAX = np.round((np.pi * CONFIG['RADMAX'] ** 2) /
                      SLA_GRD.resolution ** 2)
    logging.info('Pixel range = %s-%s', np.int(PIXMIN), np.int(PIXMAX))

    # Figure to get contours of parameter
    FIG = Figure()
    CONT_AX = FIG.add_subplot(111)

    START_TIME = datetime.now()

    logging.info('Start tracking')

    # Loop over grid
    for date, filename in DATASET_LIST:
        date = date.astype(dt.date)
        # Extract grid date
        grd_int_date = num2julian(date2num(date))
        SLA_GRD.grid_date = date

        # Initialise two eddy objects to hold data
        A_EDDY = IdentificationList('Anticyclonic', SLA_GRD, date, **CONFIG)
        C_EDDY = IdentificationList('Cyclonic', SLA_GRD, date, **CONFIG)

        A_EDDY.pixel_threshold = [PIXMIN, PIXMAX]
        C_EDDY.pixel_threshold = [PIXMIN, PIXMAX]

        logging.info('AVISO_FILE : %s', filename)

        sla = SLA_GRD.get_aviso_data(filename)
        SLA_GRD.set_mask(sla).uvmask()

        if SMOOTHING:
            if 'Gaussian' in SMOOTHING_TYPE:
                logging.info('applying Gaussian high-pass filter')
                # Set landpoints to zero
                np.place(sla, SLA_GRD.mask, 0.)
                if hasattr(sla, 'data'):
                    np.place(sla, sla.data == SLA_GRD.fillval, 0.)
                # High pass filter, see
                # http://stackoverflow.com/questions/6094957/high-pass-filter-
                # for-image-processing-in-python-by-using-scipy-numpy
                sla -= gaussian_filter(sla, [MRES, ZRES])
                logging.info('applying Gaussian high-pass filter -- OK')

            elif 'Hanning' in SMOOTHING_TYPE:
                logging.info('applying %s passes of Hanning filter',
                             SMOOTH_FAC)
                # Do SMOOTH_FAC passes of 2d Hanning filter
                sla = func_hann2d_fast(sla, SMOOTH_FAC)
                logging.info('applying %s passes of Hanning filter -- OK')

            else:
                raise Exception('Filter unknown : %s', SMOOTHING_TYPE)

        # Apply the landmask
        sla.mask += SLA_GRD.mask

        # Multiply by 0.01 for m
        SLA_GRD.set_geostrophic_velocity(sla * 0.01)

        # Remove padded boundary
        sla = sla[SLA_GRD.view_unpad]

        # Calculate EKE
        SLA_GRD.get_eke()

        if 'SLA' in DIAGNOSTIC_TYPE:
            A_EDDY.sla = sla.copy()
            C_EDDY.sla = sla.copy()

        # Get scalar speed
        A_EDDY.uspd = SLA_GRD.uspd
        C_EDDY.uspd = SLA_GRD.uspd

        # Set interpolation coefficients
        SLA_GRD.set_interp_coeffs(sla, SLA_GRD.uspd)
        A_EDDY.sla_coeffs = SLA_GRD.sla_coeffs
        A_EDDY.uspd_coeffs = SLA_GRD.uspd_coeffs
        C_EDDY.sla_coeffs = SLA_GRD.sla_coeffs
        C_EDDY.uspd_coeffs = SLA_GRD.uspd_coeffs

        if 'SLA' in DIAGNOSTIC_TYPE:
            logging.info('Processing SLA contours for eddies')
            CONTOURS = CONT_AX.contour(
                SLA_GRD.lon,
                SLA_GRD.lat,
                A_EDDY.sla,
                levels=A_EDDY.contour_parameter)
            
            # MultiThreading on path to fit circle could accelerate processing
            # may be in python 3
            #~ paths = []
            #~ for i in CONTOURS.collections:
                #~ paths += i.get_paths()
            #~ circle_process(paths)
            # Note that C_CS is in reverse order
            logging.info('Processing SLA contours for eddies -- Ok')

        # Set contour coordinates and indices for calculation of
        # speed-based radius
        A_EDDY.swirl = SwirlSpeed(CONTOURS)
        C_EDDY.swirl = A_EDDY.swirl

        # Now we loop over the CS collection
        if 'SLA' in DIAGNOSTIC_TYPE:
            logging.info("Anticyclonic research")
            A_EDDY = collection_loop(CONTOURS, SLA_GRD, grd_int_date,
                                     a_list_obj=A_EDDY, c_list_obj=None)
            # Note that C_CS is reverse order
            logging.info("Cyclonic research")
            C_EDDY = collection_loop(CONTOURS, SLA_GRD, grd_int_date,
                                     a_list_obj=None, c_list_obj=C_EDDY)

        # clear the current axis
        CONT_AX.cla()
        # Save file
        A_EDDY.write_netcdf(path=SAVE_DIR)
        C_EDDY.write_netcdf(path=SAVE_DIR)

    # Total running time
    logging.info('Mean duration by loop : %s',
                 (datetime.now() - START_TIME) / len(DATASET_LIST))
    logging.info('Duration : %s', datetime.now() - START_TIME)
    logging.info('Outputs saved to %s', SAVE_DIR)
