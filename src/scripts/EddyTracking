#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
"""

from py_eddy_tracker import EddyParser
from glob import glob
from yaml import load as yaml_load
from py_eddy_tracker.py_eddy_tracker_property_classes import \
    EddiesObservations, TrackEddiesObservations, \
    VirtualEddiesObservations
from py_eddy_tracker.tools import distance_matrix

import logging
import numpy as np
import datetime as dt


D2R = 0.017453292519943295
UINT32_MAX = 4294967295
UINT16_MAX = 65535


if __name__ == '__main__':
    # Run using:
    PARSER = EddyParser(
        "Tool to use identification step to compute tracking")
    PARSER.add_argument('yaml_file',
                        help='Yaml file to configure py-eddy-tracker')
    YAML_FILE = PARSER.parse_args().yaml_file

    # Read yaml configuration file
    with open(YAML_FILE, 'r') as stream:
        CONFIG = yaml_load(stream)

    NB_OBS_MIN = int(CONFIG['TRACK_DURATION_MIN'])
    NB_VIRTUAL_OBS_MAX_BY_SEGMENT = int(CONFIG['VIRTUAL_LEGNTH_MAX'])

    PATTERN = CONFIG['PATHS']['FILES_PATTERN']
    FILENAMES = glob(PATTERN)
    FILENAMES.sort()

    e_previous = EddiesObservations.load_from_netcdf(FILENAMES[0])

    START_TIME = dt.datetime.now()
    logging.info('Start tracking on %d files', len(FILENAMES))
    # To count id tracks
    CURRENT_ID = 0
    CORRESPONDANCES = []
    START = True
    FLG_VIRTUAL = False

    for file_name in FILENAMES[1:]:
        logging.debug('%s match with previous state', file_name)
        e_current = EddiesObservations.load_from_netcdf(file_name)
        logging.debug('%d obs to match', len(e_current))

        if FLG_VIRTUAL:
            nb_real_obs = len(e_previous)
            # If you comment this the virtual fonctionnality will be disable
            logging.debug('%d virtual obs will be add to previous',
                          len(virtual_obs))
            e_previous = e_previous.merge(virtual_obs)
        dist_result = np.empty((len(e_previous),
                                len(e_current)),
                                dtype='f8') + np.nan
        distance_matrix(
            e_previous.obs['lon'], e_previous.obs['lat'],
            e_current.obs['lon'], e_current.obs['lat'],
            dist_result)
        i_previous, i_current = np.where(dist_result < 20.)
        nb_match = i_previous.shape[0]

        logging.debug('%d match with previous', nb_match)
        correspondance = np.array(
            i_previous,
            dtype=[
                ('in', 'u2'),
                ('out', 'u2'),
                ('id', 'u4'),
                ('virtual', np.bool_),
                ('virtual_length', 'u1')])
        correspondance['out'] = i_current

        if FLG_VIRTUAL:
            correspondance['virtual'] = i_previous >= nb_real_obs
        else:
            correspondance['virtual'] = False

        if START:
            START = False
            # Set an id for each match
            correspondance['id'] = np.arange(nb_match)
            # Set counter
            CURRENT_ID += nb_match
        else:
            # We set all id to UINT32_MAX
            id_previous = np.ones(len(e_previous), dtype='u4') * UINT32_MAX
            # We get old id for previously eddies tracked
            previous_id = CORRESPONDANCES[-1]['id']
            id_previous[CORRESPONDANCES[-1]['out']] = previous_id
            correspondance['id'] = id_previous[correspondance['in']]
            if FLG_VIRTUAL:
                nb_rebirth = correspondance['virtual'].sum()
                if nb_rebirth != 0:
                    logging.debug('%d re-birth due to prolongation with'
                                  ' virtual observations', nb_rebirth)
                    # Set id for virtual
                    i_virtual = correspondance['in'][correspondance['virtual']] - nb_real_obs
                    correspondance['id'][correspondance['virtual']] = \
                        virtual_obs.obs['track'][i_virtual]
                    correspondance['virtual_length'][correspondance['virtual']] = \
                        virtual_obs.obs['segment_size'][i_virtual]

            # SECTION for virtual observation
            nb_virtual_prolongate = 0
            if FLG_VIRTUAL:
                # Save previous state to count virtual obs
                previous_virtual_obs = virtual_obs
                virtual_dead_id = np.setdiff1d(virtual_obs.obs['track'],
                                               correspondance['id'])
                list_previous_virtual_id = virtual_obs.obs['track'].tolist()
                i_virtual_dead_id = [
                    list_previous_virtual_id.index(i) for i in virtual_dead_id]
                # Virtual obs which can be prolongate
                alive_virtual_obs = virtual_obs.obs['segment_size'][i_virtual_dead_id] < NB_VIRTUAL_OBS_MAX_BY_SEGMENT
                nb_virtual_prolongate = alive_virtual_obs.sum()
                logging.debug('%d virtual obs will be prolongate on the '
                              'next step', nb_virtual_prolongate)

            # List previous id which are not use in the next step
            dead_id = np.setdiff1d(previous_id, correspondance['id'])
            nb_dead_track = len(dead_id)
            logging.debug('%d death of real obs in this step', nb_dead_track)
            # Creation of an virtual step for dead one
            virtual_obs = VirtualEddiesObservations(
                size=nb_dead_track + nb_virtual_prolongate)
            # Find mask/index on previous correspondance to extrapolate
            # position
            list_previous_id = previous_id.tolist()
            i_dead_id = [list_previous_id.index(i) for i in dead_id]

            # Selection of observations on N-2 and N-1
            obs_a = e_previous2.obs[CORRESPONDANCES[-1][i_dead_id]['in']]
            obs_b = e_previous.obs[CORRESPONDANCES[-1][i_dead_id]['out']]
            # Position N-2 : A
            # Position N-1 : B
            # Virtual Position : C
            # New position C = B + AB
            virtual_obs.obs['dlon'][:nb_dead_track
                ] = obs_b['lon'] - obs_a['lon']
            virtual_obs.obs['dlat'][:nb_dead_track
                ] = obs_b['lat'] - obs_a['lat']
            virtual_obs.obs['lon'][:nb_dead_track
                ] = obs_b['lon'] + virtual_obs.obs['dlon'][:nb_dead_track]
            virtual_obs.obs['lat'][:nb_dead_track
                ] = obs_b['lat'] + virtual_obs.obs['dlat'][:nb_dead_track]
            # Id which are prolongated
            virtual_obs.obs['track'][:nb_dead_track] = dead_id
            # Add previous virtual
            if nb_virtual_prolongate > 0:
                obs_to_prolongate = previous_virtual_obs.obs[i_virtual_dead_id][alive_virtual_obs]
                virtual_obs.obs['lon'][nb_dead_track:
                    ] = obs_to_prolongate['lon'] + obs_to_prolongate['dlon']
                virtual_obs.obs['lat'][nb_dead_track:
                    ] = obs_to_prolongate['lat'] + obs_to_prolongate['dlat']
                virtual_obs.obs['track'][nb_dead_track:
                    ] = obs_to_prolongate['track']
                virtual_obs.obs['segment_size'][nb_dead_track:
                    ] = obs_to_prolongate['segment_size']
            # Count
            virtual_obs.obs['segment_size'] += 1
            if NB_VIRTUAL_OBS_MAX_BY_SEGMENT > 0:
                FLG_VIRTUAL = True
            # END

            # new_id is equal to UINT32_MAX we must add a new ones
            # we count the number of new
            mask_new_id = correspondance['id'] == UINT32_MAX
            nb_new_tracks = mask_new_id.sum()
            logging.debug('%d birth in this step', nb_new_tracks)
            # Set new id
            correspondance['id'][mask_new_id] = np.arange(
                CURRENT_ID, CURRENT_ID + nb_new_tracks)
            # Set counter
            CURRENT_ID += nb_new_tracks

        CORRESPONDANCES.append(correspondance)

        e_previous2 = e_previous
        e_previous = e_current

    logging.info('Track finish')
    logging.info('Start merging')
    # count obs by tracks
    nb_obs_by_tracks = np.zeros(CURRENT_ID, dtype='u2') + 1
    for correspondance in CORRESPONDANCES:
        nb_obs_by_tracks[correspondance['id']] += 1
        # When start is virtual, we don't have a previous correspondance
        nb_obs_by_tracks[correspondance['id'][correspondance['virtual']]
                         ] += correspondance['virtual_length'][correspondance['virtual']]

    # Compute index of each tracks
    i_current_by_tracks = nb_obs_by_tracks.cumsum() - nb_obs_by_tracks
    # Number of global obs
    nb_obs = nb_obs_by_tracks.sum()
    logging.info('%d tracks will be create', CURRENT_ID)
    logging.info('%d observations will be join', nb_obs)
    # Start create netcdf to agglomerate all eddy
    FINAL_EDDIES = TrackEddiesObservations(size=nb_obs)

    # Calculate the index in each tracks, we compute in u4 and translate
    # in u2 (which are limited to 65535)
    logging.debug('Compute global index array (N)')
    n = np.arange(nb_obs,
                  dtype='u4') - i_current_by_tracks.repeat(nb_obs_by_tracks)
    FINAL_EDDIES.obs['n'] = np.uint16(n)
    logging.debug('Compute global track array')
    FINAL_EDDIES.obs['track'] = np.arange(CURRENT_ID).repeat(nb_obs_by_tracks)

    # Start loading identification again to save in the finals tracks
    # Load first file
    eddies_previous = EddiesObservations.load_from_netcdf(FILENAMES[0])
    # Set type of eddy with first file
    FINAL_EDDIES.sign_type = eddies_previous.sign_type

    # To know if the track start
    first_obs_save_in_tracks = np.zeros(i_current_by_tracks.shape,
                                        dtype=np.bool_)

    for i, file_name in enumerate(FILENAMES[1:]):
        # Load current file (we begin with second one)
        eddies_current = EddiesObservations.load_from_netcdf(file_name)
        # We select the list of id which are involve in the correspondance
        i_id = CORRESPONDANCES[i]['id']
        # Index where we will write in the final object
        index_final = i_current_by_tracks[i_id]

        # First obs of eddies
        m_first_obs = -first_obs_save_in_tracks[i_id]
        if m_first_obs.any():
            # Index in the current file
            index_in = CORRESPONDANCES[i]['in'][m_first_obs]
            # Copy all variable
            for var, _ in eddies_current.obs.dtype.descr:
                FINAL_EDDIES.obs[var][index_final[m_first_obs]
                    ] = eddies_previous.obs[var][index_in]
            # Increment
            i_current_by_tracks[i_id[m_first_obs]] += 1
            # Active this flag, we have only one first by tracks
            first_obs_save_in_tracks[i_id] = True
            index_final = i_current_by_tracks[i_id]

        # Index in the current file
        index_current = CORRESPONDANCES[i]['out']
        # If the flag virtual in correspondance is active,
        # the previous is virtual
        m_virtual = CORRESPONDANCES[i]['virtual']
        if m_virtual.any():
            index_virtual = index_final[m_virtual]
            # Incrementing index
            i_current_by_tracks[i_id[m_virtual]
                ] += CORRESPONDANCES[i]['virtual_length'][m_virtual]
            # Get new index
            index_final = i_current_by_tracks[i_id]

        # Copy all variable
        for var, _ in eddies_current.obs.dtype.descr:
            FINAL_EDDIES.obs[var][index_final
                ] = eddies_current.obs[var][index_current]

        # Add increment for each index used
        i_current_by_tracks[i_id] += 1
        eddies_previous = eddies_current

    # We flag obs
    FINAL_EDDIES.obs['virtual'] = FINAL_EDDIES.obs['time'] == 0

    # Localization of virtual observation
    m_i = FINAL_EDDIES.obs['virtual'] == 1
    # Count virtual observations
    nb_virtual = FINAL_EDDIES.obs['virtual'].sum()

    logging.info('%d obs are virtual (unobserved)', nb_virtual)
    logging.info('Start extrapolation of values for virtual observations')
    nb_obs = len(FINAL_EDDIES)
    index = np.arange(nb_obs)
    for var, _ in eddies_current.obs.dtype.descr:
        FINAL_EDDIES.obs[var][m_i] = np.interp(
            index[m_i],
            index[-m_i],
            FINAL_EDDIES.obs[var][-m_i])

    # Total running time
    logging.info('Mean duration by loop : %s',
                 (dt.datetime.now() - START_TIME) / (len(FILENAMES) - 1))
    logging.info('Duration : %s', dt.datetime.now() - START_TIME)

    logging.info('The longest tracks have %d observations',
                 nb_obs_by_tracks.max())

    FINAL_EDDIES.extract_longer_eddies(
        NB_OBS_MIN, nb_obs_by_tracks.repeat(nb_obs_by_tracks)).write_netcdf()



#~ previous_amp, current_amp = np.meshgrid(
    #~ e_current.obs['amplitude'], e_previous.obs['amplitude'])
#~ delta_amp = abs(current_amp - previous_amp) / previous_amp

#~ previous_radius, current_radius = np.meshgrid(
    #~ e_current.obs['radius_e'], e_previous.obs['radius_e'])
#~ delta_radius = abs(current_radius ** 2 - previous_radius ** 2) ** .5 \
#~      / previous_radius
