#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Track eddy with Identification file produce with EddyIdentification
"""
from py_eddy_tracker import EddyParser
from glob import glob
from yaml import load as yaml_load
from py_eddy_tracker.tracking import Correspondances
from os.path import exists
from os import mkdir
import logging
from numpy import unique
import datetime as dt


def usage():
    """Usage
    """
    # Run using:
    parser = EddyParser(
        "Tool to use identification step to compute tracking")
    parser.add_argument('yaml_file',
                        help='Yaml file to configure py-eddy-tracker')
    parser.add_argument('--filename',
                        default='correpondance.nc',
                        help='Filename to save correspondance')
    parser.add_argument('--save_correspondance_and_stop',
                        action='store_true',
                        help='Stop tracking after correspondance computation,'
                        ' merging can be done with EddyFinalTracking')
    args = parser.parse_args()

    # Read yaml configuration file
    with open(args.yaml_file, 'r') as stream:
        config = yaml_load(stream)
    return config, args.save_correspondance_and_stop, args.filename


if __name__ == '__main__':
    CONFIG, SAVE_STOP, FILENAME = usage()

    # Create output directory
    SAVE_DIR = CONFIG['PATHS']['SAVE_DIR']
    if not exists(SAVE_DIR):
        mkdir(SAVE_DIR)

    NB_OBS_MIN = int(CONFIG['TRACK_DURATION_MIN'])
    NB_VIRTUAL_OBS_MAX_BY_SEGMENT = int(CONFIG['VIRTUAL_LEGNTH_MAX'])

    PATTERN = CONFIG['PATHS']['FILES_PATTERN']
    FILENAMES = glob(PATTERN)
    FILENAMES.sort()

    START_TIME = dt.datetime.now()
    logging.info('Start tracking on %d files', len(FILENAMES))

    if 'CLASS' in CONFIG:
        CLASS = getattr(
            __import__(CONFIG['CLASS']['MODULE'], globals(), locals(), CONFIG['CLASS']['CLASS']),
            CONFIG['CLASS']['CLASS'])
            
    else:
        CLASS=None

    CORRESPONDANCES = Correspondances(
        datasets=FILENAMES,
        virtual=NB_VIRTUAL_OBS_MAX_BY_SEGMENT,
        class_method=CLASS)

    CORRESPONDANCES.track()
    logging.info('Track finish')
    logging.info('Start merging')
    
    if SAVE_STOP:
        CORRESPONDANCES.save(FILENAME)
        exit()
    CORRESPONDANCES.prepare_merging()

    FINAL_EDDIES = CORRESPONDANCES.merge()

    # We flag obs
    if CORRESPONDANCES.virtual:
        FINAL_EDDIES['virtual'][:] = FINAL_EDDIES['time'] == 0

        FINAL_EDDIES.filled_by_interpolation(FINAL_EDDIES['virtual'] == 1)

    # Total running time
    FULL_TIME = dt.datetime.now() - START_TIME
    logging.info('Mean duration by loop : %s',
                 FULL_TIME / (len(FILENAMES) - 1))
    logging.info('Duration : %s', FULL_TIME)

    logging.info('The longest tracks have %d observations',
                 CORRESPONDANCES.nb_obs_by_tracks.max())
    logging.info('The mean length is %d observations before filtering',
                 CORRESPONDANCES.nb_obs_by_tracks.mean())

    SUBSET_EDDIES = FINAL_EDDIES.extract_longer_eddies(
        NB_OBS_MIN,
        CORRESPONDANCES.nb_obs_by_tracks.repeat(
            CORRESPONDANCES.nb_obs_by_tracks)
        )

    logging.info('%d tracks will be saved',
                 len(unique(SUBSET_EDDIES['track'])))

    logging.info(
        'The mean length is %d observations after filtering',
        CORRESPONDANCES.nb_obs_by_tracks[
            CORRESPONDANCES.nb_obs_by_tracks >= NB_OBS_MIN
            ].mean())

    SUBSET_EDDIES.write_netcdf(path=SAVE_DIR)
